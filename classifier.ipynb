{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 102Flowers Image Classifier\n",
    "\n",
    "This is the main notebook for the project. See the associated report (WIP) for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set hyperparameters.\n",
    "training_batch_size = 64\n",
    "validation_batch_size = 64\n",
    "test_batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Switch to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "\tprint(f\"Found {torch.cuda.device_count()} GPUs. Using cuda:0.\")\n",
    "\tdevice = torch.device(\"cuda:0\")\n",
    "else:\n",
    "\tprint(\"No GPUs found, using CPU.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the images are too large. CNN can accept images of any size but the standard is for images to be resized to 224x224. This is not essential however it is common for CNN to be trained using 224x224 images. This is used due to speed. Higher image size means that classification is more accurate however will decrease the speed at which the model trains. We should experiment with model sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([transforms.Resize(256), transforms.ToTensor()]),\n",
    "    download=True,\n",
    "    # This will transform the labels into one hot encoding\n",
    "    # This may be extra work though as they are numbers 1-102\n",
    "    # target_transform=transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value = 1))\n",
    ")\n",
    "\n",
    "validation_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"val\",\n",
    "    transform=transforms.Compose([transforms.Resize(256), transforms.ToTensor()]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "testing_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"test\",\n",
    "    transform=transforms.Compose([transforms.Resize(256), transforms.ToTensor()]),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=training_batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=validation_batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=test_batch_size, shuffle=True)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = F.one_hot(torch.tensor([e for e in range(0,102)]), num_classes=102)\n",
    "onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image is 591x500 pixels\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NeuralNetwork, self).__init__()\n",
    "\t\tself.layers = nn.Sequential(\n",
    "\t\t\t#nn.ReLU(),\n",
    "   \t\t\t#nn.Conv2d(1, 6, (5,5), (1,1), (0,0)),\n",
    "\t\t\t#nn.Linear(None, 102)\n",
    "   \t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.layers(x)\n",
    "\t\treturn x\n",
    "  \n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data/flowers-102/imagelabels.mat')\n",
    "print(set(mat['labels'][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different loss functions that we can use:\n",
    "- Mean Absolute Error: torch.nn.L1Loss\n",
    "    - This should be used for regression, target contains outliers (robust at handling noise)\n",
    "- Smooth L1 Loss: torch.nn.SmoothL1Loss\n",
    "    - This should be used for regression, when features have large values (well suited to most probelms)\n",
    "- Mean Squared Error Loss (MSE): torch.nn.MSELoss\n",
    "    - This should be used for regression, numerical values are not large, the problem is not very high dimensional\n",
    "- Cross Entropy Loss : torch.nn.CrossEntropyLoss\n",
    "    - This should be used for classification tasks where we are making a confident model and we require higher precision and recall values.\n",
    "- Negative Log-Likelihood Loss : torch.nn.NLLLoss\n",
    "    - This is useful for classification, smaller quicker training and for simple tasks\n",
    "- There are various other types of loss functions available but these are inappropriate for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the above research the following the most appropriate loss function\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimiser) :\n",
    "    #Train the model\n",
    "         \n",
    "    #Compute the error of the prediction\n",
    "        \n",
    "    #Backpropagation\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    train(train_dataloader, model, loss_fn, optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
