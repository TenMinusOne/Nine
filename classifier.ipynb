{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 102Flowers Image Classifier\n",
    "\n",
    "This is the main notebook for the project. See the associated report (WIP) for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORK IN PROGRESS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import argmax\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "import torchvision.transforms as trnfrm\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import string\n",
    "import random\n",
    "import statistics\n",
    "from statistics import mean\n",
    "from statistics import stdev"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set hyperparameters.\n",
    "training_batch_size = 20 #1020\n",
    "validation_batch_size = 20 #1020\n",
    "test_batch_size = 20 #6149\n",
    "epochs = 690\n",
    "learning_rate = 0.001\n",
    "lambda1 = 0.0001\n",
    "weightDecay = 0.001\n",
    "#momentum = 0.9\n",
    "crop_size = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 GPUs. Using cuda:0.\n"
     ]
    }
   ],
   "source": [
    "# Default to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Switch to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "\tprint(f\"Found {torch.cuda.device_count()} GPUs. Using cuda:0.\")\n",
    "\tdevice = torch.device(\"cuda:0\")\n",
    "else:\n",
    "\tprint(\"No GPUs found, using CPU.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "global mean\n",
    "original_training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "        #transforms.Normalize((0.4703, 0.3986, 0.3176), (0.2957, 0.2464, 0.2804))\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "h_flipped_training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.99),\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "        #transforms.Normalize((0.4703, 0.3986, 0.3176), (0.2957, 0.2464, 0.2804))\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "v_flipped_training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomVerticalFlip(0.99),\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "        #transforms.Normalize((0.4703, 0.3986, 0.3176), (0.2957, 0.2464, 0.2804))\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "pos90_rotate_training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomRotation([89,91]),\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "        #transforms.Normalize((0.4703, 0.3986, 0.3176), (0.2957, 0.2464, 0.2804))\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "minus90_rotate_training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomRotation([-91,-89]),\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "        #transforms.Normalize((0.4703, 0.3986, 0.3176), (0.2957, 0.2464, 0.2804))\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "skewed1_training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomPerspective(p = 0.99),\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "skewed2_training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomPerspective(0.3,p = 0.99),\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "augmented_training_data = ConcatDataset([original_training_data,h_flipped_training_data,v_flipped_training_data,pos90_rotate_training_data,minus90_rotate_training_data,skewed1_training_data,skewed2_training_data])\n",
    "\n",
    "validation_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"val\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "testing_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"test\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(augmented_training_data, batch_size=training_batch_size, shuffle=True)\n",
    "#train_dataloader = DataLoader(original_training_data, batch_size=training_batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=validation_batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]], device='cuda:0'),\n",
       " torch.Size([102, 102]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications = F.one_hot(torch.tensor([e for e in range(0,102)], device=\"cuda:0\"), num_classes=102)\n",
    "classifications, classifications.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F102Classifier(nn.Module):\n",
    "    \n",
    "    \"\"\"Proper\n",
    "    def __init__(self):\n",
    "        super(F102Classifier, self).__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(3, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, bias = False, groups = 1) #3 inputs 6 hiddens\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16) #Normalizes above \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, bias = False, groups = 1) # 12 hiddens\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, bias = False, groups = 1) # 12 hiddens\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, bias = False, groups = 1) # 12 hiddens\n",
    "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, bias = False, groups = 1) # 12 hiddens\n",
    "        self.batchnorm5 = nn.BatchNorm2d(256)\n",
    "        self.fc1 = nn.Linear(6400, 6400)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(6400, 102) #102 output neurons\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.batchnorm5(x)\n",
    "        x = x.view(training_batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    #\"\"\"\n",
    "    #\"\"\"\n",
    "    def __init__(self):\n",
    "        super(F102Classifier, self).__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(3, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, bias = False, groups = 1) #3 inputs 6 hiddens\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32) #Normalizes above \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, bias = False, groups = 1) # 12 hiddens\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, bias = False, groups = 1) # 12 hiddens\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 96, 3, bias = False, groups = 1) # 12 hiddens\n",
    "        self.batchnorm4 = nn.BatchNorm2d(96)\n",
    "        self.conv5 = nn.Conv2d(96, 96, 3, bias = False, groups = 1) # 12 hiddens\n",
    "        self.batchnorm5 = nn.BatchNorm2d(96)\n",
    "        self.fc1 = nn.Linear(2400, 2400)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(2400, 102) #102 output neurons\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.batchnorm5(x)\n",
    "        x = x.view(training_batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def lambda1_loss(self, n):\n",
    "      return torch.abs(n).sum()\n",
    "    #\"\"\"\n",
    "net = F102Classifier()\n",
    "if device == torch.device(\"cuda:0\"):\n",
    "    net.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function & Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weightDecay,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    avgLoss = 0\n",
    "    for batch, (i,j) in enumerate(dataloader):\n",
    "\n",
    "        features, labels = i.to(device), j.to(device)\n",
    "\n",
    "        l1_parameters = []\n",
    "        for parameter in model.parameters():\n",
    "          l1_parameters.append(parameter.view(-1))\n",
    "        l1_regularization = lambda1 * model.lambda1_loss(torch.cat(l1_parameters))\n",
    "\n",
    "        #all_linear1_params = torch.cat([x.view(-1) for x in net.fc1.parameters()])\n",
    "        #l1_regularization = lambda1 * torch.norm(all_linear1_params, 1)\n",
    "\n",
    "        # Compute the loss based off the predictions vs labels\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions, labels) + l1_regularization\n",
    "        avgLoss += loss\n",
    "\n",
    "        #Compute back propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch+1) % len(dataloader) == 0: #after final batch of each epoch\n",
    "            avgLoss = avgLoss / training_batch_size\n",
    "            #print(\"lamda1: \" + str(l1_regularization))\n",
    "            print(f'Average Training Loss: {loss.item()}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)# - 1\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    #n = 0\n",
    "    for batch, (i,j) in enumerate(dataloader):\n",
    "        #n += 1\n",
    "        #if n < num_batches:\n",
    "\n",
    "        features, labels = i.to(device), j.to(device)\n",
    "        model.cuda()\n",
    "        pred = model(features)\n",
    "        test_loss += loss_fn(pred, labels).item()\n",
    "        #for i in range(19):\n",
    "            #if labels[i] !=argmax(pred[i]):\n",
    "                #print(\"this label \" + str(labels[i]) + \" missclassed as\" + str(argmax(pred[i])))\n",
    "        correct += (pred.argmax(1) == labels).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss : {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Training and Testing And saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Name of Model is Geu\n",
      "Epoch 1-------------\n",
      "Average Training Loss: 6.050067901611328\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 26.9%, Avg loss : 3.522724 \n",
      "\n",
      "new best, saving model for epoch 1\n",
      "Epoch 2-------------\n",
      "Average Training Loss: 4.125741004943848\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 37.7%, Avg loss : 2.939497 \n",
      "\n",
      "new best, saving model for epoch 2\n",
      "Epoch 3-------------\n",
      "Average Training Loss: 3.8035507202148438\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 44.0%, Avg loss : 2.587480 \n",
      "\n",
      "new best, saving model for epoch 3\n",
      "Epoch 4-------------\n",
      "Average Training Loss: 2.848842144012451\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 43.3%, Avg loss : 2.654286 \n",
      "\n",
      "Epoch 5-------------\n",
      "Average Training Loss: 2.496342658996582\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.9%, Avg loss : 2.656653 \n",
      "\n",
      "new best, saving model for epoch 5\n",
      "Epoch 6-------------\n",
      "Average Training Loss: 2.286550283432007\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 45.7%, Avg loss : 2.980349 \n",
      "\n",
      "Epoch 7-------------\n",
      "Average Training Loss: 2.143317937850952\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 45.4%, Avg loss : 2.807081 \n",
      "\n",
      "Epoch 8-------------\n",
      "Average Training Loss: 2.090372323989868\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 43.3%, Avg loss : 3.057495 \n",
      "\n",
      "Epoch 9-------------\n",
      "Average Training Loss: 2.07346248626709\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 44.6%, Avg loss : 3.316906 \n",
      "\n",
      "Epoch 10-------------\n",
      "Average Training Loss: 1.537107229232788\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 46.4%, Avg loss : 2.889951 \n",
      "\n",
      "Epoch 11-------------\n",
      "Average Training Loss: 1.3262741565704346\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.4%, Avg loss : 2.812665 \n",
      "\n",
      "Epoch 12-------------\n",
      "Average Training Loss: 1.3728086948394775\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.8%, Avg loss : 2.699016 \n",
      "\n",
      "new best, saving model for epoch 12\n",
      "Epoch 13-------------\n",
      "Average Training Loss: 1.548043966293335\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 45.9%, Avg loss : 2.898063 \n",
      "\n",
      "Epoch 14-------------\n",
      "Average Training Loss: 1.6419947147369385\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 45.8%, Avg loss : 3.047824 \n",
      "\n",
      "Epoch 15-------------\n",
      "Average Training Loss: 1.4006507396697998\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.7%, Avg loss : 2.843227 \n",
      "\n",
      "Epoch 16-------------\n",
      "Average Training Loss: 1.5650358200073242\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 45.2%, Avg loss : 3.067943 \n",
      "\n",
      "Epoch 17-------------\n",
      "Average Training Loss: 1.8629404306411743\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.2%, Avg loss : 2.934619 \n",
      "\n",
      "Epoch 18-------------\n",
      "Average Training Loss: 1.7995414733886719\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.3%, Avg loss : 3.232101 \n",
      "\n",
      "Epoch 19-------------\n",
      "Average Training Loss: 1.7018909454345703\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 48.6%, Avg loss : 3.064777 \n",
      "\n",
      "Epoch 20-------------\n",
      "Average Training Loss: 1.1430927515029907\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.0%, Avg loss : 2.644337 \n",
      "\n",
      "Epoch 21-------------\n",
      "Average Training Loss: 1.4843947887420654\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 48.5%, Avg loss : 2.882236 \n",
      "\n",
      "Epoch 22-------------\n",
      "Average Training Loss: 1.3543888330459595\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 46.8%, Avg loss : 3.192675 \n",
      "\n",
      "Epoch 23-------------\n",
      "Average Training Loss: 1.4125096797943115\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 48.2%, Avg loss : 3.177367 \n",
      "\n",
      "Epoch 24-------------\n",
      "Average Training Loss: 0.9332101345062256\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 52.2%, Avg loss : 2.664078 \n",
      "\n",
      "new best, saving model for epoch 24\n",
      "Epoch 25-------------\n",
      "Average Training Loss: 1.343881368637085\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.0%, Avg loss : 3.113012 \n",
      "\n",
      "Epoch 26-------------\n",
      "Average Training Loss: 1.3438729047775269\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 49.1%, Avg loss : 3.026895 \n",
      "\n",
      "Epoch 27-------------\n",
      "Average Training Loss: 1.1942139863967896\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.8%, Avg loss : 2.866791 \n",
      "\n",
      "Epoch 28-------------\n",
      "Average Training Loss: 0.8245315551757812\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 52.7%, Avg loss : 2.924773 \n",
      "\n",
      "new best, saving model for epoch 28\n",
      "Epoch 29-------------\n",
      "Average Training Loss: 1.175146222114563\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 49.6%, Avg loss : 2.982987 \n",
      "\n",
      "Epoch 30-------------\n",
      "Average Training Loss: 1.077990174293518\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.5%, Avg loss : 3.032873 \n",
      "\n",
      "Epoch 31-------------\n",
      "Average Training Loss: 0.9924706816673279\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.5%, Avg loss : 3.160545 \n",
      "\n",
      "Epoch 32-------------\n",
      "Average Training Loss: 1.293413758277893\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.3%, Avg loss : 3.192291 \n",
      "\n",
      "Epoch 33-------------\n",
      "Average Training Loss: 1.0630133152008057\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.6%, Avg loss : 3.104853 \n",
      "\n",
      "Epoch 34-------------\n",
      "Average Training Loss: 0.8843684196472168\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.5%, Avg loss : 2.848931 \n",
      "\n",
      "Epoch 35-------------\n",
      "Average Training Loss: 0.9433275461196899\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.2%, Avg loss : 2.955166 \n",
      "\n",
      "Epoch 36-------------\n",
      "Average Training Loss: 0.8459326028823853\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.7%, Avg loss : 2.803978 \n",
      "\n",
      "new best, saving model for epoch 36\n",
      "Epoch 37-------------\n",
      "Average Training Loss: 1.2313369512557983\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.0%, Avg loss : 3.194932 \n",
      "\n",
      "Epoch 38-------------\n",
      "Average Training Loss: 0.8634922504425049\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 49.5%, Avg loss : 3.057096 \n",
      "\n",
      "Epoch 39-------------\n",
      "Average Training Loss: 0.9281682372093201\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.2%, Avg loss : 2.675269 \n",
      "\n",
      "Epoch 40-------------\n",
      "Average Training Loss: 0.7487359642982483\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.3%, Avg loss : 3.002711 \n",
      "\n",
      "Epoch 41-------------\n",
      "Average Training Loss: 1.295896291732788\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 49.8%, Avg loss : 2.984284 \n",
      "\n",
      "Epoch 42-------------\n",
      "Average Training Loss: 1.7405421733856201\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 48.1%, Avg loss : 3.312055 \n",
      "\n",
      "Epoch 43-------------\n",
      "Average Training Loss: 0.8351758718490601\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 48.7%, Avg loss : 3.053270 \n",
      "\n",
      "Epoch 44-------------\n",
      "Average Training Loss: 0.59541255235672\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 55.1%, Avg loss : 2.546212 \n",
      "\n",
      "new best, saving model for epoch 44\n",
      "Epoch 45-------------\n",
      "Average Training Loss: 0.7207655906677246\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.9%, Avg loss : 2.727889 \n",
      "\n",
      "Epoch 46-------------\n",
      "Average Training Loss: 1.2500797510147095\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 52.3%, Avg loss : 2.840543 \n",
      "\n",
      "Epoch 47-------------\n",
      "Average Training Loss: 1.2579244375228882\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.4%, Avg loss : 3.024751 \n",
      "\n",
      "Epoch 48-------------\n",
      "Average Training Loss: 0.8277530670166016\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.3%, Avg loss : 3.219917 \n",
      "\n",
      "Epoch 49-------------\n",
      "Average Training Loss: 1.2343497276306152\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.5%, Avg loss : 2.778075 \n",
      "\n",
      "Epoch 50-------------\n",
      "Average Training Loss: 1.0612908601760864\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.8%, Avg loss : 3.164365 \n",
      "\n",
      "Epoch 51-------------\n",
      "Average Training Loss: 0.9694346189498901\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.7%, Avg loss : 2.839302 \n",
      "\n",
      "Epoch 52-------------\n",
      "Average Training Loss: 0.8141891360282898\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 54.3%, Avg loss : 2.736010 \n",
      "\n",
      "Epoch 53-------------\n",
      "Average Training Loss: 0.5629015564918518\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.4%, Avg loss : 2.832120 \n",
      "\n",
      "Epoch 54-------------\n",
      "Average Training Loss: 1.6957412958145142\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 49.2%, Avg loss : 3.065101 \n",
      "\n",
      "Epoch 55-------------\n",
      "Average Training Loss: 0.8789121508598328\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 52.8%, Avg loss : 2.893818 \n",
      "\n",
      "Epoch 56-------------\n",
      "Average Training Loss: 0.6173304319381714\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 54.0%, Avg loss : 2.678982 \n",
      "\n",
      "Epoch 57-------------\n",
      "Average Training Loss: 0.6616058349609375\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.8%, Avg loss : 2.874831 \n",
      "\n",
      "Epoch 58-------------\n",
      "Average Training Loss: 0.8231311440467834\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.2%, Avg loss : 2.876593 \n",
      "\n",
      "Epoch 59-------------\n",
      "Average Training Loss: 1.0064196586608887\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.0%, Avg loss : 3.067618 \n",
      "\n",
      "Epoch 60-------------\n",
      "Average Training Loss: 0.906303346157074\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.2%, Avg loss : 2.994242 \n",
      "\n",
      "Epoch 61-------------\n",
      "Average Training Loss: 0.695956289768219\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.0%, Avg loss : 2.796861 \n",
      "\n",
      "Epoch 62-------------\n",
      "Average Training Loss: 0.5604885816574097\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 54.8%, Avg loss : 2.712288 \n",
      "\n",
      "Epoch 63-------------\n",
      "Average Training Loss: 0.6903083324432373\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 49.7%, Avg loss : 2.951146 \n",
      "\n",
      "Epoch 64-------------\n",
      "Average Training Loss: 1.2349117994308472\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.8%, Avg loss : 3.057538 \n",
      "\n",
      "Epoch 65-------------\n",
      "Average Training Loss: 0.6278191804885864\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 57.1%, Avg loss : 2.553084 \n",
      "\n",
      "new best, saving model for epoch 65\n",
      "Epoch 66-------------\n",
      "Average Training Loss: 0.5032594799995422\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.1%, Avg loss : 2.619462 \n",
      "\n",
      "Epoch 67-------------\n",
      "Average Training Loss: 0.7090012431144714\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.5%, Avg loss : 2.848555 \n",
      "\n",
      "Epoch 68-------------\n",
      "Average Training Loss: 1.2714512348175049\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 49.1%, Avg loss : 3.308039 \n",
      "\n",
      "Epoch 69-------------\n",
      "Average Training Loss: 0.7858580350875854\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.0%, Avg loss : 2.784548 \n",
      "\n",
      "Epoch 70-------------\n",
      "Average Training Loss: 0.49628594517707825\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 54.3%, Avg loss : 2.705236 \n",
      "\n",
      "Epoch 71-------------\n",
      "Average Training Loss: 0.6995387673377991\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.2%, Avg loss : 2.863893 \n",
      "\n",
      "Epoch 72-------------\n",
      "Average Training Loss: 1.0100876092910767\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 51.2%, Avg loss : 3.194151 \n",
      "\n",
      "Epoch 73-------------\n",
      "Average Training Loss: 0.7847432494163513\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.3%, Avg loss : 2.934190 \n",
      "\n",
      "Epoch 74-------------\n",
      "Average Training Loss: 0.631077766418457\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 52.9%, Avg loss : 2.910285 \n",
      "\n",
      "Epoch 75-------------\n",
      "Average Training Loss: 0.750540018081665\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 54.1%, Avg loss : 2.930953 \n",
      "\n",
      "Epoch 76-------------\n",
      "Average Training Loss: 1.1039716005325317\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 48.7%, Avg loss : 3.045917 \n",
      "\n",
      "Epoch 77-------------\n",
      "Average Training Loss: 0.7899275422096252\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 54.4%, Avg loss : 2.946944 \n",
      "\n",
      "Epoch 78-------------\n",
      "Average Training Loss: 0.7654567360877991\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 55.2%, Avg loss : 2.735944 \n",
      "\n",
      "Epoch 79-------------\n",
      "Average Training Loss: 0.5199311971664429\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 55.3%, Avg loss : 2.691877 \n",
      "\n",
      "Epoch 80-------------\n",
      "Average Training Loss: 0.6090357303619385\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.2%, Avg loss : 3.036061 \n",
      "\n",
      "Epoch 81-------------\n",
      "Average Training Loss: 1.4097278118133545\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 50.5%, Avg loss : 3.139837 \n",
      "\n",
      "Epoch 82-------------\n",
      "Average Training Loss: 0.6076052188873291\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 55.1%, Avg loss : 3.027535 \n",
      "\n",
      "Epoch 83-------------\n",
      "Average Training Loss: 0.5756465792655945\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 55.0%, Avg loss : 2.789747 \n",
      "\n",
      "Epoch 84-------------\n",
      "Average Training Loss: 0.5090215802192688\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 54.1%, Avg loss : 2.857444 \n",
      "\n",
      "Epoch 85-------------\n",
      "Average Training Loss: 0.47242113947868347\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 55.3%, Avg loss : 2.669185 \n",
      "\n",
      "Epoch 86-------------\n",
      "Average Training Loss: 1.9479146003723145\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 47.6%, Avg loss : 3.411724 \n",
      "\n",
      "Epoch 87-------------\n",
      "Average Training Loss: 0.7023022174835205\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 53.9%, Avg loss : 2.841227 \n",
      "\n",
      "Epoch 88-------------\n",
      "Average Training Loss: 0.5783657431602478\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 52.5%, Avg loss : 2.830791 \n",
      "\n",
      "Epoch 89-------------\n",
      "Average Training Loss: 0.461886465549469\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 52.8%, Avg loss : 2.792776 \n",
      "\n",
      "Epoch 90-------------\n",
      "Average Training Loss: 1.381608247756958\n",
      "\n",
      "Validation Test\n",
      "Accuracy: 49.1%, Avg loss : 3.206322 \n",
      "\n",
      "Epoch 91-------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     train(train_dataloader, net, loss_function, optimiser)\n\u001b[0;32m     11\u001b[0m     \u001b[39m#print(\"Training Test\")\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[39m#test(train_dataloader, net, loss_function)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation Test\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(dataloader, model, loss_fn, optimizer):\n\u001b[0;32m      2\u001b[0m     avgLoss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     \u001b[39mfor\u001b[39;00m batch, (i,j) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m      5\u001b[0m         features, labels \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mto(device), j\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m         l1_parameters \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:243\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torchvision\\datasets\\flowers102.py:81\u001b[0m, in \u001b[0;36mFlowers102.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, Any]:\n\u001b[0;32m     80\u001b[0m     image_file, label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_files[idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_labels[idx]\n\u001b[1;32m---> 81\u001b[0m     image \u001b[39m=\u001b[39m PIL\u001b[39m.\u001b[39;49mImage\u001b[39m.\u001b[39;49mopen(image_file)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[0;32m     84\u001b[0m         image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\PIL\\Image.py:3245\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3242\u001b[0m     fp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(fp\u001b[39m.\u001b[39mread())\n\u001b[0;32m   3243\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m-> 3245\u001b[0m prefix \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mread(\u001b[39m16\u001b[39m)\n\u001b[0;32m   3247\u001b[0m preinit()\n\u001b[0;32m   3249\u001b[0m accept_warnings \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\"\"\"\n",
    "best = 0\n",
    "upperLetters = string.ascii_uppercase\n",
    "lowerLetters = string.ascii_lowercase\n",
    "name = random.choice(upperLetters) + random.choice(lowerLetters) + random.choice(lowerLetters)\n",
    "print(\"Random Name of Model is \" + name)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}-------------')\n",
    "    train(train_dataloader, net, loss_function, optimiser)\n",
    "    #print(\"Training Test\")\n",
    "    #test(train_dataloader, net, loss_function)\n",
    "    print(\"Validation Test\")\n",
    "    current = test(validation_dataloader, net, loss_function)\n",
    "    if current > best:\n",
    "        print(\"new best, saving model for epoch \" + str(t+1))\n",
    "        best = current\n",
    "        save_path = \"./models/classifier\" + name+  \"Epoch\" + str(t+1) + \"Accuracy\" + str(int(100*best))+ \".pth\"\n",
    "        torch.save(net.state_dict(), save_path)\n",
    "print('Finished Training, Testing and Saving')\n",
    "#\"\"\"\n",
    "\"\"\"\n",
    "Pmodel = F102Classifier()\n",
    "Pmodel.load_state_dict(torch.load(\"./models/classifierTmkEpoch186Accuracy54.pth\"))\n",
    "test(validation_dataloader, Pmodel, loss_function)\n",
    "#test(test_dataloader, Pmodel, loss_function) \n",
    "#\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Keeping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" 30,0.001 = 15.2%\n",
    " 100, 0.001 = 14.3%\n",
    " 50, 0.001 = 16.4%\n",
    " 30,0.01 = 1.0%  Herma-OF\"\"\"\n",
    "\n",
    "\"\"\"For Theo\t\n",
    "\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3) \n",
    "\t\tself.conv2 = nn.Conv2d(6, 12, 3)\n",
    "\t\tself.conv3 = nn.Conv2d(12, 24, 3)\n",
    "\t\tself.conv4 = nn.Conv2d(24, 48, 3)\n",
    "\t\tself.conv5 = nn.Conv2d(48, 96, 3)\n",
    "\t\tself.fc1 = nn.Linear(384, 1024)\n",
    "\t\tself.fc2 = nn.Linear(1024, 512)\n",
    "\t\tself.fc3 = nn.Linear(512, 102)\t\n",
    "30, 0.01 = 1.0%\n",
    "30, 0.001 = 14.0%\n",
    "100, 0.001 = 13.2%\n",
    "30, 0.0001 = 7.2%\n",
    "\n",
    "\t\tself.pool = nn.AvgPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 12, 3)\n",
    "\t\tself.conv2 = nn.Conv2d(12, 48, 3)\n",
    "\t\tself.conv3 = nn.Conv2d(48, 96, 3)\n",
    "\t\tself.fc1 = nn.Linear(18816, 1024)\n",
    "\t\tself.fc2 = nn.Linear(1024, 512)\n",
    "\t\tself.fc3 = nn.Linear(512, 102)\t\t\n",
    "100, 0.001 = 9.5%\n",
    "30, 0.001 = 17.8%\n",
    "50, 0.001 = 1.0%\n",
    "\n",
    "\t\tself.pool = nn.AvgPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 12, 3)\n",
    "\t\tself.fc1 = nn.Linear(47628, 102)\n",
    "30, 0.001 = 19.9%\n",
    "\n",
    "\t\tself.pool = nn.AvgPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.fc1 = nn.Linear(23814, 102)\n",
    "30, 0.001 = 17.9%\n",
    "15, 0.001 = 16.0%\n",
    "10, 0.001 = 19.0%\n",
    "5, 0.001 = 14.4%\n",
    "\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.fc1 = nn.Linear(23814, 102)\n",
    "30, 0.001 = 19.2%\n",
    "10, 0.001 = 16.8%\n",
    "50, 0.001 = 17.0\n",
    "\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.conv2 = nn.Conv2d(6, 12, 3)\n",
    "\t\tself.conv3 = nn.Conv2d(12, 24, 3)\n",
    "\t\tself.conv4 = nn.Conv2d(24, 48, 3)\n",
    "\t\tself.conv5 = nn.Conv2d(48, 96, 3)\n",
    "\t\tself.fc1 = nn.Linear(384, 102)\n",
    "30, 0.001 = 18.6%\n",
    "\n",
    "MORE\n",
    "self.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.conv2 = nn.Conv2d(6, 12, 3)\n",
    "\t\tself.conv3 = nn.Conv2d(12, 24, 3)\n",
    "\t\tself.fc1 = nn.Linear(21600, 102)\n",
    "\tdef forward(self, x):\n",
    "\t\tx = (F.relu(self.conv1(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv2(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv3(x)))\n",
    "\t\tx = x.view(training_batch_size, -1)\n",
    "\t\tx = self.fc1(x)\n",
    "        5 epochs = 10.5%\n",
    "        10 epochs = 17.2%\n",
    "        30 epochs = 16.1%\n",
    "        15 epochs = 10.9\n",
    "        \n",
    "        Same as above but kernel size 4 and self.fc1 = nn.Linear(18816, 102)\n",
    "        10 epochs = 9.2%\n",
    "        15 epochs = 19.2%\n",
    "        20 epochs = 21.5%\n",
    "        25 epochs = 14.5%\n",
    "        30 epochs = 18.4%\n",
    "        \n",
    "        Same as above but kernal size 8 and self.fc1 = nn.Linear(15000, 102)\n",
    "        20 epochs = 15.4 %\n",
    "        30 epochs = 25.5%\n",
    "        35 epochs = 16.1%\n",
    "        \n",
    "        Same as above but with batch normilization after conv1\n",
    "        20 epochs = 12.9%\n",
    "        25 epochs = 25.0%\n",
    "        30 epochs = 19.6%\n",
    "        40 epochs = 18.0%\n",
    "        \n",
    "        Same as above but with dropout of 0.5 after conv1 and batch normilization\n",
    "        10 epochs = 7.3%\n",
    "        15 epochs = 9.1%\n",
    "        20 epochs = 12.4%\n",
    "        30 epochs = 10.3%\n",
    "        40 epochs = 11.6%\n",
    "        \n",
    "        Same as above but dropout set to 0.2\n",
    "        20 epochs = 10.5%\n",
    "        25 epochs = 16.2%\n",
    "        30 epochs = 16.7%\n",
    "        32 epochs = 12.6%\n",
    "        35 epochs = 19.1%\n",
    "        40 epochs = 13.5%\n",
    "        50 epochs = 9.3%\n",
    "        \n",
    "        Now have implemented testing per epoch, now will just record the peak epoch.\n",
    "\n",
    "        Same as above but with conv3 removed and self.fc1 = nn.Linear(8112, 102)\n",
    "        50 epochs = 28.0%\n",
    "        \n",
    "        Same as above but modified conv2 to have 6 outputs and nn.Linear(4056, 102)\n",
    "        20 epochs = 20.0%\n",
    "        Reverting to previous conv2 and fcl\n",
    "        \n",
    "        Now reverted, applying data augmentation: horizontal flip, vertical flip, 90 degree rotates, -90 degree rotates\n",
    "        \n",
    "        Turns out it wasn't properly applying augmentations, I'm using less exact values for the randomness so it basically always does it.\n",
    "        4 epochs = 32.5%\n",
    "\n",
    "        Same as above but without the vertical flipping\n",
    "        5 epochs = 30.9%\n",
    "        It seems vertical flipping is beneficial\n",
    "\n",
    "        Same as before but with vertical flipping back and additionally 45 and -45 rotation augments\n",
    "        4 epochs = 32.3%\n",
    "\n",
    "        Same as before but removing both 45 degree rotation augments and setting dropout rate at 0.3\n",
    "        3 epochs = 29%\n",
    "\n",
    "        Same as before but setting dropout rate to 0.1\n",
    "        2 epochs = 20.2%\n",
    "\n",
    "        Same as before but setting dropout rate to 0.25\n",
    "        6 epochs = 26.7%\n",
    "\n",
    "        Restting dropout rate back to 0.2 and now testing it on the training data to see if the loss function is the issue\n",
    "        6 epochs 31.4%\n",
    "        Loss function is maybe fine\n",
    "\n",
    "        same as before but removing batch normilization\n",
    "        9 epochs = 31.7%\n",
    "        without normilization accuracy increases slower but is more consistently high, will continue without it for now\n",
    "\n",
    "        Same as before but pool kernal of 4 self.fc1 = nn.Linear(10092, 102)\n",
    "        20 epochs = 30.8%\n",
    "        Current model as follows:\n",
    "        self.pool = nn.MaxPool2d(8, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\t#self.batchnorm1 = nn.BatchNorm2d(6)\n",
    "\t\tself.dropout = nn.Dropout2d(0.2)\n",
    "\t\tself.conv2 = nn.Conv2d(6, 12, 3)\n",
    "\t\t#self.conv3 = nn.Conv2d(3, 24, 3)\n",
    "\t\tself.fc1 = nn.Linear(8112, 102)\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.pool(F.relu(self.conv1(x)))\n",
    "\t\t#x = self.batchnorm1(x)\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = self.pool(F.relu(self.conv2(x)))\n",
    "\t\tx = x.view(training_batch_size, -1)\n",
    "\t\tx = self.fc1(x)\n",
    "\n",
    "        Massive change, new model below\n",
    "        def __init__(self):\n",
    "\t\tsuper(F102Classifier, self).__init__()\n",
    "\t\t\n",
    "\t\tself.pool = nn.MaxPool2d(8, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3) #3 inputs 6 hiddens\n",
    "\t\tself.batchnorm1 = nn.BatchNorm2d(6) #Normalizes above \n",
    "\t\tself.conv2 = nn.Conv2d(6, 30, 3) # 12 hiddens\n",
    "\t\tself.batchnorm2 = nn.BatchNorm2d(30)\n",
    "\t\tself.conv3 = nn.Conv2d(30, 30, 9) # 12 hiddens\n",
    "\t\tself.batchnorm3 = nn.BatchNorm2d(30)\n",
    "\t\tself.fc1 = nn.Linear(1080, 204)\n",
    "\t\tself.dropout = nn.Dropout(0.2)\n",
    "\t\tself.fc2 = nn.Linear(204, 102) #102 output neurons\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.pool(F.relu(self.conv1(x)))\n",
    "\t\tx = self.batchnorm1(x)\n",
    "\t\tx = self.pool(F.relu(self.conv2(x)))\n",
    "\t\tx = self.batchnorm2(x)\n",
    "\t\tx = self.pool(F.relu(self.conv3(x)))\n",
    "\t\tx = self.batchnorm3(x)\n",
    "\t\tx = x.view(training_batch_size, -1)\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x\n",
    "        14 epochs = 42.5%\n",
    "        \n",
    "        Experimented with different crop size, 128 seems best. Also now are saving the models of the best epochs so good ones are not lost\n",
    "\n",
    "\t\timplementing random names, L1 and L2 regularisation\n",
    "\t\tSck epoch 13, accuracy = 45%\n",
    "\n",
    "\t\timplementing additional augmentation with random perspectives\n",
    "\n",
    "\t\tRecognising the importance of high channel outputs, lol\n",
    "\t\t\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 32, 3, bias = False, groups = 1) #3 inputs 6 hiddens\n",
    "\t\tself.batchnorm1 = nn.BatchNorm2d(32) #Normalizes above \n",
    "\t\tself.conv2 = nn.Conv2d(32, 64, 3, bias = False, groups = 1) # 12 hiddens\n",
    "\t\tself.batchnorm2 = nn.BatchNorm2d(64)\n",
    "\t\tself.conv3 = nn.Conv2d(64, 64, 3, bias = False, groups = 1) # 12 hiddens\n",
    "\t\tself.batchnorm3 = nn.BatchNorm2d(64)\n",
    "\t\tself.conv4 = nn.Conv2d(64, 64, 3, bias = False, groups = 1) # 12 hiddens\n",
    "\t\tself.batchnorm4 = nn.BatchNorm2d(64)\n",
    "\t\tself.conv5 = nn.Conv2d(64, 64, 3, bias = False, groups = 1) # 12 hiddens\n",
    "\t\tself.batchnorm5 = nn.BatchNorm2d(64)\n",
    "\t\tself.fc1 = nn.Linear(2304, 2304)\n",
    "\t\tself.dropout = nn.Dropout(0.2)\n",
    "\t\tself.fc2 = nn.Linear(2304, 102) #102 output neurons\n",
    "\tdef forward(self, x):\n",
    "\t\tx = F.relu(self.conv1(x))\n",
    "\t\tx = self.batchnorm1(x)\n",
    "\t\tx = self.pool(F.relu(self.conv2(x)))\n",
    "\t\tx = self.batchnorm2(x)\n",
    "\t\tx = self.pool(F.relu(self.conv3(x)))\n",
    "\t\tx = self.batchnorm3(x)\n",
    "\t\tx = self.pool(F.relu(self.conv4(x)))\n",
    "\t\tx = self.batchnorm4(x)\n",
    "\t\tx = self.pool(F.relu(self.conv5(x)))\n",
    "\t\tx = self.batchnorm5(x)\n",
    "\t\tx = x.view(training_batch_size, -1)\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\t#x = self.dropout(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x\n",
    "\t\tlearning_rate = 0.001\n",
    "\t\tlambda1 = 0.001\n",
    "\t\tweightDecay = 0.001\n",
    "\t\t#momentum = 0.9\n",
    "\t\tcrop_size = 128\n",
    "\n",
    "\t\tTmk shown in discord has 47% (peak of 55% but took a while)\n",
    "\t\tExx has 128 output channels in final layers but seems to overfit more, 44%\n",
    "\t\tQba is Exx but with dropout, accuracy is increasing and overfitting less, 50%\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this label tensor(28, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(87, device='cuda:0')\n",
      "this label tensor(89, device='cuda:0') missclassed astensor(45, device='cuda:0')\n",
      "this label tensor(44, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(47, device='cuda:0') missclassed astensor(14, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(37, device='cuda:0') missclassed astensor(78, device='cuda:0')\n",
      "this label tensor(38, device='cuda:0') missclassed astensor(71, device='cuda:0')\n",
      "this label tensor(78, device='cuda:0') missclassed astensor(9, device='cuda:0')\n",
      "this label tensor(61, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(34, device='cuda:0') missclassed astensor(54, device='cuda:0')\n",
      "this label tensor(24, device='cuda:0') missclassed astensor(3, device='cuda:0')\n",
      "this label tensor(37, device='cuda:0') missclassed astensor(78, device='cuda:0')\n",
      "this label tensor(19, device='cuda:0') missclassed astensor(6, device='cuda:0')\n",
      "this label tensor(100, device='cuda:0') missclassed astensor(82, device='cuda:0')\n",
      "this label tensor(8, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(91, device='cuda:0') missclassed astensor(98, device='cuda:0')\n",
      "this label tensor(100, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(51, device='cuda:0') missclassed astensor(43, device='cuda:0')\n",
      "this label tensor(74, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(19, device='cuda:0') missclassed astensor(74, device='cuda:0')\n",
      "this label tensor(80, device='cuda:0') missclassed astensor(41, device='cuda:0')\n",
      "this label tensor(68, device='cuda:0') missclassed astensor(31, device='cuda:0')\n",
      "this label tensor(58, device='cuda:0') missclassed astensor(70, device='cuda:0')\n",
      "this label tensor(81, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(18, device='cuda:0')\n",
      "this label tensor(101, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(73, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(29, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(20, device='cuda:0') missclassed astensor(45, device='cuda:0')\n",
      "this label tensor(69, device='cuda:0') missclassed astensor(43, device='cuda:0')\n",
      "this label tensor(35, device='cuda:0') missclassed astensor(6, device='cuda:0')\n",
      "this label tensor(33, device='cuda:0') missclassed astensor(43, device='cuda:0')\n",
      "this label tensor(32, device='cuda:0') missclassed astensor(60, device='cuda:0')\n",
      "this label tensor(32, device='cuda:0') missclassed astensor(74, device='cuda:0')\n",
      "this label tensor(98, device='cuda:0') missclassed astensor(84, device='cuda:0')\n",
      "this label tensor(6, device='cuda:0') missclassed astensor(68, device='cuda:0')\n",
      "this label tensor(1, device='cuda:0') missclassed astensor(66, device='cuda:0')\n",
      "this label tensor(96, device='cuda:0') missclassed astensor(40, device='cuda:0')\n",
      "this label tensor(70, device='cuda:0') missclassed astensor(99, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(71, device='cuda:0') missclassed astensor(43, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(43, device='cuda:0') missclassed astensor(10, device='cuda:0')\n",
      "this label tensor(79, device='cuda:0') missclassed astensor(29, device='cuda:0')\n",
      "this label tensor(67, device='cuda:0') missclassed astensor(18, device='cuda:0')\n",
      "this label tensor(35, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(62, device='cuda:0') missclassed astensor(45, device='cuda:0')\n",
      "this label tensor(94, device='cuda:0') missclassed astensor(87, device='cuda:0')\n",
      "this label tensor(23, device='cuda:0') missclassed astensor(26, device='cuda:0')\n",
      "this label tensor(8, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(100, device='cuda:0')\n",
      "this label tensor(78, device='cuda:0') missclassed astensor(56, device='cuda:0')\n",
      "this label tensor(15, device='cuda:0') missclassed astensor(49, device='cuda:0')\n",
      "this label tensor(27, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(42, device='cuda:0') missclassed astensor(79, device='cuda:0')\n",
      "this label tensor(35, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(30, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(4, device='cuda:0') missclassed astensor(25, device='cuda:0')\n",
      "this label tensor(27, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(26, device='cuda:0') missclassed astensor(5, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(98, device='cuda:0')\n",
      "this label tensor(71, device='cuda:0') missclassed astensor(75, device='cuda:0')\n",
      "this label tensor(79, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(12, device='cuda:0') missclassed astensor(90, device='cuda:0')\n",
      "this label tensor(94, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(45, device='cuda:0') missclassed astensor(4, device='cuda:0')\n",
      "this label tensor(96, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(18, device='cuda:0') missclassed astensor(83, device='cuda:0')\n",
      "this label tensor(46, device='cuda:0') missclassed astensor(11, device='cuda:0')\n",
      "this label tensor(61, device='cuda:0') missclassed astensor(77, device='cuda:0')\n",
      "this label tensor(61, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(98, device='cuda:0') missclassed astensor(7, device='cuda:0')\n",
      "this label tensor(81, device='cuda:0') missclassed astensor(71, device='cuda:0')\n",
      "this label tensor(34, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(18, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(19, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(84, device='cuda:0') missclassed astensor(44, device='cuda:0')\n",
      "this label tensor(0, device='cuda:0') missclassed astensor(33, device='cuda:0')\n",
      "this label tensor(95, device='cuda:0') missclassed astensor(17, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(17, device='cuda:0') missclassed astensor(76, device='cuda:0')\n",
      "this label tensor(13, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(33, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(19, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(5, device='cuda:0') missclassed astensor(45, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(42, device='cuda:0')\n",
      "this label tensor(52, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(20, device='cuda:0') missclassed astensor(100, device='cuda:0')\n",
      "this label tensor(7, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(42, device='cuda:0') missclassed astensor(44, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(3, device='cuda:0')\n",
      "this label tensor(66, device='cuda:0') missclassed astensor(69, device='cuda:0')\n",
      "this label tensor(23, device='cuda:0') missclassed astensor(91, device='cuda:0')\n",
      "this label tensor(38, device='cuda:0') missclassed astensor(91, device='cuda:0')\n",
      "this label tensor(93, device='cuda:0') missclassed astensor(19, device='cuda:0')\n",
      "this label tensor(77, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(81, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(19, device='cuda:0') missclassed astensor(63, device='cuda:0')\n",
      "this label tensor(67, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(77, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(3, device='cuda:0') missclassed astensor(39, device='cuda:0')\n",
      "this label tensor(101, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(47, device='cuda:0') missclassed astensor(46, device='cuda:0')\n",
      "this label tensor(40, device='cuda:0') missclassed astensor(91, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(94, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(16, device='cuda:0') missclassed astensor(66, device='cuda:0')\n",
      "this label tensor(34, device='cuda:0') missclassed astensor(32, device='cuda:0')\n",
      "this label tensor(93, device='cuda:0') missclassed astensor(16, device='cuda:0')\n",
      "this label tensor(42, device='cuda:0') missclassed astensor(71, device='cuda:0')\n",
      "this label tensor(21, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(73, device='cuda:0') missclassed astensor(60, device='cuda:0')\n",
      "this label tensor(6, device='cuda:0') missclassed astensor(94, device='cuda:0')\n",
      "this label tensor(65, device='cuda:0') missclassed astensor(4, device='cuda:0')\n",
      "this label tensor(95, device='cuda:0') missclassed astensor(6, device='cuda:0')\n",
      "this label tensor(14, device='cuda:0') missclassed astensor(11, device='cuda:0')\n",
      "this label tensor(22, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(50, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(43, device='cuda:0') missclassed astensor(29, device='cuda:0')\n",
      "this label tensor(25, device='cuda:0') missclassed astensor(88, device='cuda:0')\n",
      "this label tensor(13, device='cuda:0') missclassed astensor(34, device='cuda:0')\n",
      "this label tensor(81, device='cuda:0') missclassed astensor(28, device='cuda:0')\n",
      "this label tensor(17, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(35, device='cuda:0') missclassed astensor(3, device='cuda:0')\n",
      "this label tensor(92, device='cuda:0') missclassed astensor(75, device='cuda:0')\n",
      "this label tensor(28, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(7, device='cuda:0') missclassed astensor(58, device='cuda:0')\n",
      "this label tensor(57, device='cuda:0') missclassed astensor(88, device='cuda:0')\n",
      "this label tensor(48, device='cuda:0') missclassed astensor(78, device='cuda:0')\n",
      "this label tensor(95, device='cuda:0') missclassed astensor(101, device='cuda:0')\n",
      "this label tensor(39, device='cuda:0') missclassed astensor(99, device='cuda:0')\n",
      "this label tensor(72, device='cuda:0') missclassed astensor(17, device='cuda:0')\n",
      "this label tensor(91, device='cuda:0') missclassed astensor(65, device='cuda:0')\n",
      "this label tensor(23, device='cuda:0') missclassed astensor(26, device='cuda:0')\n",
      "this label tensor(3, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(47, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(77, device='cuda:0') missclassed astensor(68, device='cuda:0')\n",
      "this label tensor(23, device='cuda:0') missclassed astensor(73, device='cuda:0')\n",
      "this label tensor(3, device='cuda:0') missclassed astensor(94, device='cuda:0')\n",
      "this label tensor(94, device='cuda:0') missclassed astensor(50, device='cuda:0')\n",
      "this label tensor(21, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(23, device='cuda:0') missclassed astensor(99, device='cuda:0')\n",
      "this label tensor(30, device='cuda:0') missclassed astensor(25, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(35, device='cuda:0') missclassed astensor(90, device='cuda:0')\n",
      "this label tensor(79, device='cuda:0') missclassed astensor(73, device='cuda:0')\n",
      "this label tensor(66, device='cuda:0') missclassed astensor(83, device='cuda:0')\n",
      "this label tensor(90, device='cuda:0') missclassed astensor(101, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(42, device='cuda:0')\n",
      "this label tensor(86, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(79, device='cuda:0') missclassed astensor(25, device='cuda:0')\n",
      "this label tensor(3, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(1, device='cuda:0') missclassed astensor(60, device='cuda:0')\n",
      "this label tensor(41, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(54, device='cuda:0') missclassed astensor(75, device='cuda:0')\n",
      "this label tensor(2, device='cuda:0') missclassed astensor(54, device='cuda:0')\n",
      "this label tensor(79, device='cuda:0') missclassed astensor(30, device='cuda:0')\n",
      "this label tensor(88, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(20, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(94, device='cuda:0') missclassed astensor(75, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(14, device='cuda:0')\n",
      "this label tensor(50, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(22, device='cuda:0') missclassed astensor(86, device='cuda:0')\n",
      "this label tensor(73, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(47, device='cuda:0') missclassed astensor(14, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(20, device='cuda:0')\n",
      "this label tensor(53, device='cuda:0') missclassed astensor(70, device='cuda:0')\n",
      "this label tensor(75, device='cuda:0') missclassed astensor(44, device='cuda:0')\n",
      "this label tensor(22, device='cuda:0') missclassed astensor(86, device='cuda:0')\n",
      "this label tensor(101, device='cuda:0') missclassed astensor(5, device='cuda:0')\n",
      "this label tensor(88, device='cuda:0') missclassed astensor(46, device='cuda:0')\n",
      "this label tensor(77, device='cuda:0') missclassed astensor(87, device='cuda:0')\n",
      "this label tensor(38, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(88, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(36, device='cuda:0') missclassed astensor(100, device='cuda:0')\n",
      "this label tensor(27, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(2, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(76, device='cuda:0') missclassed astensor(13, device='cuda:0')\n",
      "this label tensor(25, device='cuda:0') missclassed astensor(4, device='cuda:0')\n",
      "this label tensor(96, device='cuda:0') missclassed astensor(99, device='cuda:0')\n",
      "this label tensor(41, device='cuda:0') missclassed astensor(14, device='cuda:0')\n",
      "this label tensor(101, device='cuda:0') missclassed astensor(5, device='cuda:0')\n",
      "this label tensor(48, device='cuda:0') missclassed astensor(72, device='cuda:0')\n",
      "this label tensor(94, device='cuda:0') missclassed astensor(50, device='cuda:0')\n",
      "this label tensor(55, device='cuda:0') missclassed astensor(73, device='cuda:0')\n",
      "this label tensor(30, device='cuda:0') missclassed astensor(90, device='cuda:0')\n",
      "this label tensor(23, device='cuda:0') missclassed astensor(60, device='cuda:0')\n",
      "this label tensor(3, device='cuda:0') missclassed astensor(84, device='cuda:0')\n",
      "this label tensor(86, device='cuda:0') missclassed astensor(94, device='cuda:0')\n",
      "this label tensor(52, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(44, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(38, device='cuda:0') missclassed astensor(71, device='cuda:0')\n",
      "this label tensor(7, device='cuda:0') missclassed astensor(51, device='cuda:0')\n",
      "this label tensor(42, device='cuda:0') missclassed astensor(75, device='cuda:0')\n",
      "this label tensor(49, device='cuda:0') missclassed astensor(11, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(92, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(20, device='cuda:0') missclassed astensor(26, device='cuda:0')\n",
      "this label tensor(64, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(61, device='cuda:0') missclassed astensor(5, device='cuda:0')\n",
      "this label tensor(27, device='cuda:0') missclassed astensor(32, device='cuda:0')\n",
      "this label tensor(25, device='cuda:0') missclassed astensor(44, device='cuda:0')\n",
      "this label tensor(88, device='cuda:0') missclassed astensor(52, device='cuda:0')\n",
      "this label tensor(26, device='cuda:0') missclassed astensor(88, device='cuda:0')\n",
      "this label tensor(92, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(87, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(0, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(24, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(68, device='cuda:0')\n",
      "this label tensor(77, device='cuda:0') missclassed astensor(79, device='cuda:0')\n",
      "this label tensor(80, device='cuda:0') missclassed astensor(83, device='cuda:0')\n",
      "this label tensor(87, device='cuda:0') missclassed astensor(77, device='cuda:0')\n",
      "this label tensor(78, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(28, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(66, device='cuda:0') missclassed astensor(34, device='cuda:0')\n",
      "this label tensor(1, device='cuda:0') missclassed astensor(6, device='cuda:0')\n",
      "this label tensor(42, device='cuda:0') missclassed astensor(77, device='cuda:0')\n",
      "this label tensor(89, device='cuda:0') missclassed astensor(79, device='cuda:0')\n",
      "this label tensor(42, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(91, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(67, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(51, device='cuda:0') missclassed astensor(43, device='cuda:0')\n",
      "this label tensor(73, device='cuda:0') missclassed astensor(42, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(30, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(78, device='cuda:0') missclassed astensor(21, device='cuda:0')\n",
      "this label tensor(21, device='cuda:0') missclassed astensor(40, device='cuda:0')\n",
      "this label tensor(29, device='cuda:0') missclassed astensor(94, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(31, device='cuda:0')\n",
      "this label tensor(29, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(87, device='cuda:0') missclassed astensor(36, device='cuda:0')\n",
      "this label tensor(28, device='cuda:0') missclassed astensor(31, device='cuda:0')\n",
      "this label tensor(30, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(52, device='cuda:0') missclassed astensor(88, device='cuda:0')\n",
      "this label tensor(80, device='cuda:0') missclassed astensor(47, device='cuda:0')\n",
      "this label tensor(84, device='cuda:0') missclassed astensor(94, device='cuda:0')\n",
      "this label tensor(95, device='cuda:0') missclassed astensor(82, device='cuda:0')\n",
      "this label tensor(53, device='cuda:0') missclassed astensor(16, device='cuda:0')\n",
      "this label tensor(98, device='cuda:0') missclassed astensor(10, device='cuda:0')\n",
      "this label tensor(38, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(75, device='cuda:0') missclassed astensor(18, device='cuda:0')\n",
      "this label tensor(42, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(77, device='cuda:0') missclassed astensor(68, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(74, device='cuda:0')\n",
      "this label tensor(52, device='cuda:0') missclassed astensor(41, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(29, device='cuda:0')\n",
      "this label tensor(96, device='cuda:0') missclassed astensor(78, device='cuda:0')\n",
      "this label tensor(47, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(29, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(93, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(68, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(91, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(93, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(37, device='cuda:0') missclassed astensor(78, device='cuda:0')\n",
      "this label tensor(49, device='cuda:0') missclassed astensor(14, device='cuda:0')\n",
      "this label tensor(82, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(18, device='cuda:0') missclassed astensor(32, device='cuda:0')\n",
      "this label tensor(50, device='cuda:0') missclassed astensor(84, device='cuda:0')\n",
      "this label tensor(45, device='cuda:0') missclassed astensor(14, device='cuda:0')\n",
      "this label tensor(19, device='cuda:0') missclassed astensor(14, device='cuda:0')\n",
      "this label tensor(73, device='cuda:0') missclassed astensor(45, device='cuda:0')\n",
      "this label tensor(75, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(41, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(76, device='cuda:0') missclassed astensor(28, device='cuda:0')\n",
      "this label tensor(21, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(41, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(92, device='cuda:0') missclassed astensor(54, device='cuda:0')\n",
      "this label tensor(35, device='cuda:0') missclassed astensor(65, device='cuda:0')\n",
      "this label tensor(91, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(8, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(51, device='cuda:0') missclassed astensor(55, device='cuda:0')\n",
      "this label tensor(72, device='cuda:0') missclassed astensor(74, device='cuda:0')\n",
      "this label tensor(91, device='cuda:0') missclassed astensor(98, device='cuda:0')\n",
      "this label tensor(89, device='cuda:0') missclassed astensor(99, device='cuda:0')\n",
      "this label tensor(7, device='cuda:0') missclassed astensor(10, device='cuda:0')\n",
      "this label tensor(3, device='cuda:0') missclassed astensor(25, device='cuda:0')\n",
      "this label tensor(20, device='cuda:0') missclassed astensor(10, device='cuda:0')\n",
      "this label tensor(46, device='cuda:0') missclassed astensor(40, device='cuda:0')\n",
      "this label tensor(61, device='cuda:0') missclassed astensor(55, device='cuda:0')\n",
      "this label tensor(44, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(74, device='cuda:0') missclassed astensor(1, device='cuda:0')\n",
      "this label tensor(6, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(67, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(79, device='cuda:0') missclassed astensor(86, device='cuda:0')\n",
      "this label tensor(22, device='cuda:0') missclassed astensor(86, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(39, device='cuda:0')\n",
      "this label tensor(87, device='cuda:0') missclassed astensor(94, device='cuda:0')\n",
      "this label tensor(4, device='cuda:0') missclassed astensor(88, device='cuda:0')\n",
      "this label tensor(35, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(71, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(30, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(84, device='cuda:0') missclassed astensor(100, device='cuda:0')\n",
      "this label tensor(20, device='cuda:0') missclassed astensor(7, device='cuda:0')\n",
      "this label tensor(47, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(3, device='cuda:0')\n",
      "this label tensor(91, device='cuda:0') missclassed astensor(67, device='cuda:0')\n",
      "this label tensor(33, device='cuda:0') missclassed astensor(77, device='cuda:0')\n",
      "this label tensor(72, device='cuda:0') missclassed astensor(101, device='cuda:0')\n",
      "this label tensor(56, device='cuda:0') missclassed astensor(16, device='cuda:0')\n",
      "this label tensor(75, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(100, device='cuda:0')\n",
      "this label tensor(83, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(38, device='cuda:0') missclassed astensor(87, device='cuda:0')\n",
      "this label tensor(76, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(95, device='cuda:0') missclassed astensor(68, device='cuda:0')\n",
      "this label tensor(48, device='cuda:0') missclassed astensor(78, device='cuda:0')\n",
      "this label tensor(52, device='cuda:0') missclassed astensor(18, device='cuda:0')\n",
      "this label tensor(51, device='cuda:0') missclassed astensor(55, device='cuda:0')\n",
      "this label tensor(13, device='cuda:0') missclassed astensor(34, device='cuda:0')\n",
      "this label tensor(18, device='cuda:0') missclassed astensor(75, device='cuda:0')\n",
      "this label tensor(82, device='cuda:0') missclassed astensor(25, device='cuda:0')\n",
      "this label tensor(96, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(87, device='cuda:0')\n",
      "this label tensor(88, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(25, device='cuda:0') missclassed astensor(67, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(95, device='cuda:0') missclassed astensor(88, device='cuda:0')\n",
      "this label tensor(27, device='cuda:0') missclassed astensor(24, device='cuda:0')\n",
      "this label tensor(32, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(7, device='cuda:0') missclassed astensor(48, device='cuda:0')\n",
      "this label tensor(51, device='cuda:0') missclassed astensor(64, device='cuda:0')\n",
      "this label tensor(76, device='cuda:0') missclassed astensor(34, device='cuda:0')\n",
      "this label tensor(87, device='cuda:0') missclassed astensor(29, device='cuda:0')\n",
      "this label tensor(56, device='cuda:0') missclassed astensor(76, device='cuda:0')\n",
      "this label tensor(13, device='cuda:0') missclassed astensor(15, device='cuda:0')\n",
      "this label tensor(100, device='cuda:0') missclassed astensor(42, device='cuda:0')\n",
      "this label tensor(66, device='cuda:0') missclassed astensor(84, device='cuda:0')\n",
      "this label tensor(72, device='cuda:0') missclassed astensor(54, device='cuda:0')\n",
      "this label tensor(40, device='cuda:0') missclassed astensor(91, device='cuda:0')\n",
      "this label tensor(77, device='cuda:0') missclassed astensor(68, device='cuda:0')\n",
      "this label tensor(35, device='cuda:0') missclassed astensor(6, device='cuda:0')\n",
      "this label tensor(67, device='cuda:0') missclassed astensor(64, device='cuda:0')\n",
      "this label tensor(24, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(76, device='cuda:0') missclassed astensor(12, device='cuda:0')\n",
      "this label tensor(25, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(92, device='cuda:0') missclassed astensor(77, device='cuda:0')\n",
      "this label tensor(71, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(37, device='cuda:0') missclassed astensor(34, device='cuda:0')\n",
      "this label tensor(98, device='cuda:0') missclassed astensor(71, device='cuda:0')\n",
      "this label tensor(82, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(71, device='cuda:0') missclassed astensor(59, device='cuda:0')\n",
      "this label tensor(72, device='cuda:0') missclassed astensor(73, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(65, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(75, device='cuda:0') missclassed astensor(67, device='cuda:0')\n",
      "this label tensor(15, device='cuda:0') missclassed astensor(41, device='cuda:0')\n",
      "this label tensor(41, device='cuda:0') missclassed astensor(14, device='cuda:0')\n",
      "this label tensor(52, device='cuda:0') missclassed astensor(26, device='cuda:0')\n",
      "this label tensor(49, device='cuda:0') missclassed astensor(4, device='cuda:0')\n",
      "this label tensor(6, device='cuda:0') missclassed astensor(19, device='cuda:0')\n",
      "this label tensor(26, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(39, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(12, device='cuda:0') missclassed astensor(84, device='cuda:0')\n",
      "this label tensor(40, device='cuda:0') missclassed astensor(99, device='cuda:0')\n",
      "this label tensor(14, device='cuda:0') missclassed astensor(62, device='cuda:0')\n",
      "this label tensor(43, device='cuda:0') missclassed astensor(71, device='cuda:0')\n",
      "this label tensor(90, device='cuda:0') missclassed astensor(101, device='cuda:0')\n",
      "this label tensor(17, device='cuda:0') missclassed astensor(45, device='cuda:0')\n",
      "this label tensor(33, device='cuda:0') missclassed astensor(55, device='cuda:0')\n",
      "this label tensor(61, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(37, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(52, device='cuda:0') missclassed astensor(80, device='cuda:0')\n",
      "this label tensor(43, device='cuda:0') missclassed astensor(25, device='cuda:0')\n",
      "this label tensor(43, device='cuda:0') missclassed astensor(74, device='cuda:0')\n",
      "this label tensor(72, device='cuda:0') missclassed astensor(30, device='cuda:0')\n",
      "this label tensor(100, device='cuda:0') missclassed astensor(42, device='cuda:0')\n",
      "this label tensor(29, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(2, device='cuda:0') missclassed astensor(77, device='cuda:0')\n",
      "this label tensor(87, device='cuda:0') missclassed astensor(19, device='cuda:0')\n",
      "this label tensor(54, device='cuda:0') missclassed astensor(61, device='cuda:0')\n",
      "this label tensor(21, device='cuda:0') missclassed astensor(76, device='cuda:0')\n",
      "this label tensor(89, device='cuda:0') missclassed astensor(79, device='cuda:0')\n",
      "this label tensor(71, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(82, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(100, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(69, device='cuda:0') missclassed astensor(33, device='cuda:0')\n",
      "this label tensor(61, device='cuda:0') missclassed astensor(62, device='cuda:0')\n",
      "this label tensor(1, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(29, device='cuda:0')\n",
      "this label tensor(28, device='cuda:0') missclassed astensor(32, device='cuda:0')\n",
      "this label tensor(39, device='cuda:0') missclassed astensor(43, device='cuda:0')\n",
      "this label tensor(82, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(17, device='cuda:0') missclassed astensor(5, device='cuda:0')\n",
      "this label tensor(15, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(7, device='cuda:0') missclassed astensor(4, device='cuda:0')\n",
      "this label tensor(95, device='cuda:0') missclassed astensor(96, device='cuda:0')\n",
      "this label tensor(17, device='cuda:0') missclassed astensor(39, device='cuda:0')\n",
      "this label tensor(14, device='cuda:0') missclassed astensor(58, device='cuda:0')\n",
      "this label tensor(30, device='cuda:0') missclassed astensor(71, device='cuda:0')\n",
      "this label tensor(96, device='cuda:0') missclassed astensor(32, device='cuda:0')\n",
      "this label tensor(38, device='cuda:0') missclassed astensor(2, device='cuda:0')\n",
      "this label tensor(79, device='cuda:0') missclassed astensor(85, device='cuda:0')\n",
      "this label tensor(64, device='cuda:0') missclassed astensor(54, device='cuda:0')\n",
      "this label tensor(87, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(39, device='cuda:0') missclassed astensor(47, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(3, device='cuda:0')\n",
      "this label tensor(15, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(10, device='cuda:0') missclassed astensor(94, device='cuda:0')\n",
      "this label tensor(54, device='cuda:0') missclassed astensor(32, device='cuda:0')\n",
      "this label tensor(95, device='cuda:0') missclassed astensor(72, device='cuda:0')\n",
      "this label tensor(56, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(90, device='cuda:0') missclassed astensor(56, device='cuda:0')\n",
      "this label tensor(32, device='cuda:0') missclassed astensor(9, device='cuda:0')\n",
      "this label tensor(68, device='cuda:0') missclassed astensor(72, device='cuda:0')\n",
      "this label tensor(66, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(73, device='cuda:0') missclassed astensor(72, device='cuda:0')\n",
      "this label tensor(48, device='cuda:0') missclassed astensor(95, device='cuda:0')\n",
      "this label tensor(32, device='cuda:0') missclassed astensor(27, device='cuda:0')\n",
      "this label tensor(50, device='cuda:0') missclassed astensor(0, device='cuda:0')\n",
      "this label tensor(17, device='cuda:0') missclassed astensor(93, device='cuda:0')\n",
      "this label tensor(2, device='cuda:0') missclassed astensor(75, device='cuda:0')\n",
      "this label tensor(42, device='cuda:0') missclassed astensor(73, device='cuda:0')\n",
      "this label tensor(97, device='cuda:0') missclassed astensor(81, device='cuda:0')\n",
      "this label tensor(44, device='cuda:0') missclassed astensor(11, device='cuda:0')\n",
      "this label tensor(52, device='cuda:0') missclassed astensor(99, device='cuda:0')\n",
      "this label tensor(39, device='cuda:0') missclassed astensor(59, device='cuda:0')\n",
      "this label tensor(47, device='cuda:0') missclassed astensor(4, device='cuda:0')\n",
      "this label tensor(81, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(79, device='cuda:0') missclassed astensor(89, device='cuda:0')\n",
      "this label tensor(87, device='cuda:0') missclassed astensor(6, device='cuda:0')\n",
      "this label tensor(69, device='cuda:0') missclassed astensor(30, device='cuda:0')\n",
      "this label tensor(31, device='cuda:0') missclassed astensor(44, device='cuda:0')\n",
      "this label tensor(100, device='cuda:0') missclassed astensor(79, device='cuda:0')\n",
      "this label tensor(32, device='cuda:0') missclassed astensor(92, device='cuda:0')\n",
      "this label tensor(39, device='cuda:0') missclassed astensor(68, device='cuda:0')\n",
      "this label tensor(24, device='cuda:0') missclassed astensor(8, device='cuda:0')\n",
      "this label tensor(17, device='cuda:0') missclassed astensor(5, device='cuda:0')\n",
      "this label tensor(8, device='cuda:0') missclassed astensor(24, device='cuda:0')\n",
      "this label tensor(89, device='cuda:0') missclassed astensor(25, device='cuda:0')\n",
      "this label tensor(91, device='cuda:0') missclassed astensor(82, device='cuda:0')\n",
      "this label tensor(78, device='cuda:0') missclassed astensor(37, device='cuda:0')\n",
      "this label tensor(2, device='cuda:0') missclassed astensor(18, device='cuda:0')\n",
      "this label tensor(93, device='cuda:0') missclassed astensor(84, device='cuda:0')\n",
      "this label tensor(37, device='cuda:0') missclassed astensor(22, device='cuda:0')\n",
      "this label tensor(76, device='cuda:0') missclassed astensor(28, device='cuda:0')\n",
      "this label tensor(71, device='cuda:0') missclassed astensor(84, device='cuda:0')\n",
      "this label tensor(16, device='cuda:0') missclassed astensor(35, device='cuda:0')\n",
      "Accuracy: 54.6%, Avg loss : 3.132084 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.546078431372549"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pmodel = F102Classifier()\n",
    "Pmodel.load_state_dict(torch.load(\"./models/classifierTmkEpoch81Accuracy54.pth\"))\n",
    "test(validation_dataloader, Pmodel, loss_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
