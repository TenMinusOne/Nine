{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 102Flowers Image Classifier\n",
    "\n",
    "This is the main notebook for the project. See the associated report (WIP) for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document trains the model and gives an accuracy of roughly 15% after 100 epochs.\n",
    "The problem with this is that it is overfitting to the training set and therefore it will not predict correctly for a new dataset of flowers. Therefore there is a a very low accuracy using the verification training set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set hyperparameters.\n",
    "training_batch_size = 20\n",
    "validation_batch_size = 20\n",
    "test_batch_size = 20\n",
    "epochs = 30\n",
    "learning_rate = 0.001\n",
    "#momentum = 0.9\n",
    "crop_size = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 GPUs. Using cuda:0.\n"
     ]
    }
   ],
   "source": [
    "# Default to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Switch to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "\tprint(f\"Found {torch.cuda.device_count()} GPUs. Using cuda:0.\")\n",
    "\tdevice = torch.device(\"cuda:0\")\n",
    "else:\n",
    "\tprint(\"No GPUs found, using CPU.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "validation_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"val\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "testing_data = datasets.Flowers102(\n",
    "    root = \"data\",\n",
    "    split = \"test\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=training_batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=validation_batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]], device='cuda:0'),\n",
       " torch.Size([102, 102]))"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications = F.one_hot(torch.tensor([e for e in range(0,102)], device=\"cuda:0\"), num_classes=102)\n",
    "classifications, classifications.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F102Classifier(nn.Module):\n",
    "    \n",
    "\tdef __init__(self):\n",
    "\t\tsuper(F102Classifier, self).__init__()\n",
    "\t\t\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.conv2 = nn.Conv2d(6, 12, 3)\n",
    "\t\tself.conv3 = nn.Conv2d(12, 24, 3)\n",
    "\t\tself.conv4 = nn.Conv2d(24, 48, 3)\n",
    "\t\tself.conv5 = nn.Conv2d(48, 96, 3)\n",
    "\t\tself.fc1 = nn.Linear(384, 102)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.pool(F.relu(self.conv1(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv2(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv3(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv4(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv5(x)))\n",
    "\t\t#print(\"after conv1: \", x.size())\n",
    "\t\t\n",
    "\t\tx = torch.flatten(x)\n",
    "\t\t#print(\"after flatten: \", x.size())\n",
    "\t\tx = x.view(training_batch_size, -1)\n",
    "\t\t#print(\"after view: \", x.size())\n",
    "\t\t#x = F.relu(self.fc1(x))\n",
    "\t\tx = self.fc1(x)\n",
    "\t\t#print(\"after fc3: \", x.size())\n",
    "\t\t#print(x)\n",
    "\t\t#print(x.size())\n",
    "\t\treturn x\n",
    "\n",
    "net = F102Classifier()\n",
    "if device == torch.device(\"cuda:0\"):\n",
    "\tnet.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function & Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "\tepoch = 1\n",
    "\tfor batch, (i,j) in enumerate(dataloader):\n",
    "\t\tfeatures, labels = i.to(device), j.to(device)\n",
    "  \n",
    "\t\t# Compute the loss based off the predictions vs labels\n",
    "\t\tpredictions = model(features)\n",
    "\t\tloss = loss_fn(predictions, labels)\n",
    "\n",
    "\t\t#Compute back propagation\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tif (batch+1) % 51 == 0:\n",
    "\t\t\tprint(f'Average Loss in Epoch: {loss.item()}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    for batch, (i,j) in enumerate(dataloader):\n",
    "        features, labels = i.to(device), j.to(device)\n",
    "        model.cuda()\n",
    "        pred = model(features)\n",
    "        test_loss += loss_fn(pred, labels).item()\n",
    "        correct += (pred.argmax(1) == labels).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss : {test_loss:>8f} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (20x86400 and 384x102)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[383], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     train(train_dataloader, net, loss_function, optimiser)\n\u001b[0;32m      5\u001b[0m test(validation_dataloader, net, loss_function)\n",
      "Cell \u001b[1;32mIn[381], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      4\u001b[0m features, labels \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mto(device), j\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Compute the loss based off the predictions vs labels\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m predictions \u001b[39m=\u001b[39m model(features)\n\u001b[0;32m      8\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(predictions, labels)\n\u001b[0;32m     10\u001b[0m \u001b[39m#Compute back propagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[379], line 21\u001b[0m, in \u001b[0;36mF102Classifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(training_batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39m#print(\"after view: \", x.size())\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m#x = F.relu(self.fc1(x))\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)\n\u001b[0;32m     22\u001b[0m \u001b[39m#print(\"after fc3: \", x.size())\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m#print(x)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m#print(x.size())\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Theod\\OneDrive\\Documents\\GitHub\\Nine\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (20x86400 and 384x102)"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}-------------')\n",
    "    train(train_dataloader, net, loss_function, optimiser)\n",
    "\n",
    "test(validation_dataloader, net, loss_function)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 30,0.001 = 15.2%\n",
    " 100, 0.001 = 14.3%\n",
    " 50, 0.001 = 16.4%\n",
    " 30,0.01 = 1.0%  Herma-OF\"\"\"\n",
    "\n",
    "\"\"\"For Theo\t\n",
    "\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.conv2 = nn.Conv2d(6, 12, 3)\n",
    "\t\tself.conv3 = nn.Conv2d(12, 24, 3)\n",
    "\t\tself.conv4 = nn.Conv2d(24, 48, 3)\n",
    "\t\tself.conv5 = nn.Conv2d(48, 96, 3)\n",
    "\t\tself.fc1 = nn.Linear(384, 1024)\n",
    "\t\tself.fc2 = nn.Linear(1024, 512)\n",
    "\t\tself.fc3 = nn.Linear(512, 102)\t\n",
    "30, 0.01 = 1.0%\n",
    "30, 0.001 = 14.0%\n",
    "100, 0.001 = 13.2%\n",
    "30, 0.0001 = 7.2%\n",
    "\n",
    "\t\tself.pool = nn.AvgPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 12, 3)\n",
    "\t\tself.conv2 = nn.Conv2d(12, 48, 3)\n",
    "\t\tself.conv3 = nn.Conv2d(48, 96, 3)\n",
    "\t\tself.fc1 = nn.Linear(18816, 1024)\n",
    "\t\tself.fc2 = nn.Linear(1024, 512)\n",
    "\t\tself.fc3 = nn.Linear(512, 102)\t\t\n",
    "100, 0.001 = 9.5%\n",
    "30, 0.001 = 17.8%\n",
    "50, 0.001 = 1.0%\n",
    "\n",
    "\t\tself.pool = nn.AvgPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 12, 3)\n",
    "\t\tself.fc1 = nn.Linear(47628, 102)\n",
    "30, 0.001 = 19.9%\n",
    "\n",
    "\t\tself.pool = nn.AvgPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.fc1 = nn.Linear(23814, 102)\n",
    "30, 0.001 = 17.9%\n",
    "15, 0.001 = 16.0%\n",
    "10, 0.001 = 19.0%\n",
    "5, 0.001 = 14.4%\n",
    "\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.fc1 = nn.Linear(23814, 102)\n",
    "30, 0.001 = 19.2%\n",
    "10, 0.001 = 16.8%\n",
    "50, 0.001 = 17.0\n",
    "\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\t\tself.conv2 = nn.Conv2d(6, 12, 3)\n",
    "\t\tself.conv3 = nn.Conv2d(12, 24, 3)\n",
    "\t\tself.conv4 = nn.Conv2d(24, 48, 3)\n",
    "\t\tself.conv5 = nn.Conv2d(48, 96, 3)\n",
    "\t\tself.fc1 = nn.Linear(384, 102)\n",
    "30, 0.001 = 18.6%\n",
    " \"\"\"\n",
    "save_path = \"./models/classifier.pth\"\n",
    "torch.save(net.state_dict(), save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
